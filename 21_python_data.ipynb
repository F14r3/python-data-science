{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data science in Python\n",
    "\n",
    "- Course GitHub repo: https://github.com/pycam/python-data-science\n",
    "- Python website: https://www.python.org/ \n",
    "\n",
    "## Session 2.1: Working with Pandas\n",
    "\n",
    "- [Reading CSV Data Using Pandas](#Reading-CSV-Data-Using-Pandas)\n",
    "- [Exploring our data](#Exploring-our-data)\n",
    "- [DataFrame manipulation](#DataFrame-manipulation)\n",
    "- [Exercise 2.1.1](#Exercise-2.1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mind map\n",
    "\n",
    "<img src=\"img/mind_maps/mind_maps.004.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading CSV Data Using Pandas\n",
    "\n",
    "### Import the Pandas library\n",
    "\n",
    "Pandas is a widely-used external Python library for statistics, particularly on tabular data.\n",
    "It borrows many features from R’s dataframes.\n",
    "A dataframe is a 2-dimentional table whose columns have names and potentially have different data types.\n",
    "\n",
    "Pandas website http://pandas.pydata.org/ and documentation http://pandas.pydata.org/pandas-docs/stable/.\n",
    "\n",
    "To load `pandas` into your environment, you first need to install it using `pip install pandas` as it is an external third-party library, it is not included by default when you install Python.\n",
    "\n",
    "When installed, to load it, use `import pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV data\n",
    "\n",
    "For reading a Comma Separate Values (CSV) data file with pandas, we use `pandas.read_csv()`:\n",
    "\n",
    "- Argument is the name of the file to be read.\n",
    "- Assign result to a variable to store the data that was read.\n",
    "\n",
    "\n",
    "The columns in a dataframe are the observed variables, and the rows are the observations. We are going to load a slightly different Gapminder dataset for Oceania, where each columns represent the GDP per capita on different years and each rows a country in Oceania. \n",
    "\n",
    "Pandas uses backslash `\\` to show wrapped lines when output is too wide to fit the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('data/gapminder_gdp_oceania.csv', index_col='country')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our course stores its data files in a `data/` sub-directory, which is why the path to the file is `data/gapminder_gdp_oceania.csv`. If you forget to include `data/`, or if you include it but your copy of the file is somewhere else, you will get a runtime error that ends with a line like this:\n",
    "```\n",
    "FileNotFoundError: File b'gapminder_gdp_oceania.csv' does not exist\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring our data\n",
    "\n",
    "A DataFrame is a 2-dimensional data structure that can store data of different types (including characters, integers, floating point values, factors and more) in columns. It is similar to a spreadsheet or an SQL table or the `data.frame` in R. A DataFrame always has an index (0-based). An index refers to the position of an element in the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, it’s a `DataFrame` (or, to use the full name that Python uses to refer to it internally, a `pandas.core.frame.DataFrame`).\n",
    "\n",
    "It has 2 rows and 13 columns. It uses 288 bytes of memory.\n",
    "\n",
    "The row headings are numbers (0 and 1 in this case) but we really want to index this DataFrame by country. To do so, we pass the name of the column to `read_csv()` as its `index_col` parameter to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('data/gapminder_gdp_oceania.csv', index_col='country')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `type()` function to see what kind of thing data is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what kind of things does data contain, DataFrames have an attribute called dtypes which returns the data type of each columns. Note that this is an attribute associated to the DataFrame data, and not a method. So do not use `()` to call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has now 2 rows named 'Australia' and 'New Zealand' and 12 columns, each of which has two actual 64-bit floating point values. It uses 208 bytes of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to summarize and access the data stored in DataFrames, using attributes and methods provided by the [DataFrame object](https://pandas.pydata.org/pandas-docs/stable/api.html#dataframe).\n",
    "\n",
    "To access an attribute, use the DataFrame object name followed by the attribute name `df_object.attribute`. Using the DataFrame `data` and attribute `columns`, an index of all the column names in the DataFrame can be accessed with `data.columns`.\n",
    "\n",
    "Methods are called in a similar fashion using the syntax `df_object.method()`. As an example, `data.head()` gets the first few rows in the DataFrame `data` using the `head()` method. With a method, we can supply extra information in the parenthesis as arguments to control behaviour.\n",
    "\n",
    "Let’s look at the data using these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load European's data to have more rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_data = pandas.read_csv('data/gapminder_gdp_europe.csv', index_col='country')\n",
    "print(eu_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out what the head() method does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(eu_data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often want to calculate summary statistics grouped by subsets or attributes within fields of our data. For example, we might want to calculate the average GDP per capita for 1962.\n",
    "\n",
    "We can calculate basic statistics for all records in a single column using the syntax below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_data.gdpPercap_1962.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_data['gdpPercap_1962'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract one specific metric if we wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_data['gdpPercap_1962'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_data['gdpPercap_1962'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas function `describe()` will return descriptive stats including: mean, median, max, min, std and count for a particular column in the data. Pandas’ describe function will only return summary values for columns containing numeric data.\n",
    "\n",
    "It is not particularly useful with few records, but it could be very helpful when there are thousands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame manipulation\n",
    "\n",
    "### Pandas Cheat Sheet\n",
    "[Pandas Cheat Sheet](http://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "df = pandas.DataFrame({'gene': ['BRCA2', 'TNFAIP3', 'TCF7'], \n",
    "                       'chrom': ['13', '6', '5'],\n",
    "                       'len': [84195, 16099, 37155]}\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting columns and rows\n",
    "Select just one column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or the first two rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine these to get the first 2 rows of the column 'len':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:2]['len']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be done using **positional indexing** and `.iloc[]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:2,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or to get the first 2 rows of all columns from indexed 1 till the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:2,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been using positional indexing so far, but we can also use **label-based indexing** with `.loc[]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:1,'chrom':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values('len')\n",
    "print(sorted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values('len', ascending=False)\n",
    "print(sorted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1.1\n",
    "\n",
    "- Read the data in `gapminder_gdp_americas.csv` (which should be in the same directory as `gapminder_gdp_oceania.csv`) into a variable called `americas_data` and display its summary statistics.\n",
    "- As well as the `read_csv()` function for reading data from a file, Pandas provides a `to_csv()` function to write dataframes to files. Applying what you’ve learned about reading from files, write one of your dataframes to a file called `processed.csv`. You can use help to get information on how to use `to_csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating data with Pandas (live coding session)\n",
    "\n",
    "Let's now open a new Jupyter notebook, and explore another dataset `GRCm38.gff3` from the `data/` folder.\n",
    "\n",
    "[GFF is a standard file format](http://gmod.org/wiki/GFF3) for storing genomic features in a text file. GFF stands for Generic Feature Format. GFF files are plain text, 9 column, tab-delimited files. \n",
    "\n",
    "The 9 columns of the annotation section are as follows:\n",
    "\n",
    "- Column 1: \"seqid\" - The ID of the landmark used to establish the coordinate system for the current feature.\n",
    "- Column 2: \"source\" - The source is a free text qualifier intended to describe the algorithm or operating procedure that generated this feature. \n",
    "- Column 3: \"type\" - The type of the feature.\n",
    "- Columns 4 & 5: \"start\" and \"end\" - The start and end of the feature.\n",
    "- Column 6: \"score\" - The score of the feature, a floating point number.\n",
    "- Column 7: \"strand\" - The strand of the feature.\n",
    "- Column 8: \"phase\" - For features of type \"CDS\", the phase indicates where the feature begins with reference to the reading frame. \n",
    "- Column 9: \"attributes\" - A list of feature attributes in the format tag=value. \n",
    "\n",
    "We have modified these files and added a 10th column \"gbid\" which is the GenBank ID of each feature, and taken a random subset of these features for each species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next session\n",
    "\n",
    "Go to our next notebook: [Session 2.2: Data visualisation with Matplotlib](22_python_data.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
